{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Реализация классификатора $KFDA$ (Kernel Fisher Discriminant Analysis):\n",
    "(Примеры использования и анализ см. в других файлах)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Необходимые модули:\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "import scipy\n",
    "from scipy.spatial import distance\n",
    "import math\n",
    "from  scipy import stats, linalg, exp\n",
    "from sklearn.neighbors import KNeighborsClassifier  \n",
    "import nbimporter\n",
    "from numpy import linalg\n",
    "from sklearn.svm import SVC\n",
    "import scipy.io as sio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "class KFDACl(BaseEstimator, ClassifierMixin): #Класс, для реализации KFDA\n",
    "    def __init__(self, kernel = 'RBF', gamma = 'auto', c= None, d = None, Alg = 'SVM'):\n",
    "        \"\"\"    \n",
    "               parameters:\n",
    "               kernel - string, тип ядра: linear, Polynomial, RBF\n",
    "               gamma - float, параметр RBF kernel. Если gamma = 'auto', то gamma = '1/n', где n - размерность пространства)\n",
    "               c, d - int,  параметры Polynomial kernel(cвободный член и степень соответсвенно)\n",
    "               Alg - string, способ классификации после понижения размерности: KNN, SVM\n",
    "        \"\"\"\n",
    "        self.kernel = kernel\n",
    "        self.gamma = gamma\n",
    "        self.c = c\n",
    "        self.d = d\n",
    "        self.Alg = Alg\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        input:\n",
    "               X - np.ndarray, матрица признаков объектов  nxk \n",
    "               y - np.array, вектор меток классов nx1 \n",
    "        \"\"\"\n",
    "        if (self.gamma =='auto'):\n",
    "            self.gamma = 1/(X.shape[1])\n",
    "        self.labels_ = np.unique(y) # находим значение меток классов\n",
    "        self.Cl_ = len(self.labels_) #Кол-во классов\n",
    "        self.cl_ = [np.nonzero(y == self.labels_[i])[0] for i in range(0,self.Cl_)]\n",
    "        Cl =self.Cl_\n",
    "        K = self.Kernelmtrx(X, X) \n",
    "        #Разделяем образцы по классам\n",
    "        Xcl = [X[self.cl_[i],:] for i in range(0,Cl)]\n",
    "        #Кол-во образцов в каждом из классов\n",
    "        ni = [Xcl[i].shape[0] for i in range (0,Cl)]\n",
    "        n= sum(ni)\n",
    "        #Вычисляем kernel matrix\n",
    "        Ki = [K[:,np.nonzero(y == self.labels_[i])[0]] for i in range(0,Cl)]\n",
    "        #Вычисляем Mi\n",
    "        Mi = [np.mean(Ki[i], axis= 1) for i in range (0,Cl)]\n",
    "        M0 = np.array([np.mean(K, axis=1)])\n",
    "        M = np.zeros((n,n))\n",
    "        for i in range (0,Cl):\n",
    "            M = M + np.dot((M0-Mi[i]).T, M0-Mi[i])\n",
    "        #Вычисляем Ni\n",
    "        I = [np.eye(ni[i]) for i in range (0,Cl)]\n",
    "        O = [1/float(ni[i]) for i in range (0,Cl)]\n",
    "        T = [(I[i] - O[i]) for i in range (0, Cl)]\n",
    "        Ni = [np.dot(Ki[i], np.dot(T[i], Ki[i].T)) for i in range (0, Cl)]\n",
    "        #Добавляем mu (для регуляризации)\n",
    "        eps=np.eye((n))\n",
    "        eps = eps * 0.001\n",
    "        N= sum(Ni) + eps\n",
    "        e, v = np.linalg.eigh(M) #находим собственные значения и вектора M\n",
    "        eps = np.ones(len(e))*abs(min(e))\n",
    "        e = e + 2*eps\n",
    "        sqrtE = [math.sqrt(x) for x in e]\n",
    "        sqrtM =  np.dot(np.dot(v,np.diag(sqrtE)), np.matrix.transpose(v))\n",
    "        S = np.dot(sqrtM, np.dot(np.linalg.inv(N), sqrtM))\n",
    "        eigenValues, eigenVectors = scipy.linalg.eigh(S)\n",
    "        self.alpha_ = np.zeros((eigenVectors.shape[0], Cl-1)) #alpha, вектор/матрица для проекции данных в расширенном простр-ве\n",
    "        idx = eigenValues.argsort()[::-1] \n",
    "        eigenValues = eigenValues[idx]\n",
    "        eigenVectors = eigenVectors[:,idx]\n",
    "        #alpha матрица для проекции, состоящая из Сl-1 собств векторов, соотв. Сl-1 наиб. собств. значениям матрицы S:\n",
    "        for i in range (0, Cl):\n",
    "            self.alpha_[:,i-1] =  np.dot(np.linalg.inv(sqrtM),eigenVectors[:, Cl-i-1])\n",
    "        Z=np.dot(K,self.alpha_)\n",
    "        # Значение образцов в проекции в Сl-1 пространство:\n",
    "        self.X_red_ = Z.reshape(Z.shape[0],(Cl-1))\n",
    "        self.Xtr_= X \n",
    "        # После понижения размерности, для спроектированных данных строим предсказательную модель:\n",
    "        if (self.Alg == 'KNN'):\n",
    "                \n",
    "                PrModel = KNeighborsClassifier(n_neighbors=5)  \n",
    "                PrModel.fit(self.X_red_, y)  \n",
    "                self.PrModel_=PrModel\n",
    "                print (PrModel.score(self.X_red_,y))         \n",
    "                \n",
    "        if (self.Alg == 'SVM'):\n",
    "            if (self.Cl_ == 2): \n",
    "                PrModel= SVC(kernel = 'linear', probability =True)\n",
    "            else:\n",
    "                PrModel= SVC(probability =True)\n",
    "            PrModel.fit(self.X_red_, y)\n",
    "            self.PrModel_=PrModel\n",
    "        return self\n",
    "    def predict(self,Xtst):\n",
    "        \"\"\"\n",
    "        input: Xtst - np.ndarray, матрица признаков объектов, для которых необх предсказать класс, mxk\n",
    "        output:\n",
    "               ypred - вектор предсказанный меток классов для объектов из Xpr, mx1\n",
    "        \"\"\"\n",
    "        Cl = self.Cl_\n",
    "        Kpr = self.Kernelmtrx(self.Xtr_, Xtst) \n",
    "        Xtst_red = np.dot(Kpr, self.alpha_) #Проектируем данные в уже найденное (в ф-ции fit) (Cl-1) мерное подпространство\n",
    "        Xtst_red = Xtst_red.reshape(Xtst_red.shape[0],(Cl-1))\n",
    "        ypred = np.zeros((Xtst_red.shape[0],1))\n",
    "        #После проекции вектора в (Cl-1) мерное пространство определяем его к классу по построенной (в ф-ции fit)  предс модели:\n",
    "        y_pred = self.PrModel_.predict(Xtst_red)  \n",
    "        return y_pred\n",
    "    def predict_proba(self, Xtst):\n",
    "        Cl = self.Cl_\n",
    "        Kpr = self.Kernelmtrx(self.Xtr_, Xtst) \n",
    "        w = self.alpha_\n",
    "        Xtst_red = np.dot(Kpr, w) \n",
    "        Xtst_red = Xtst_red.reshape(Xtst_red.shape[0],(Cl-1)) \n",
    "        return self.PrModel_.predict_proba(Xtst_red)\n",
    "    def decision_function(self, Xtst):\n",
    "        Cl = self.Cl_\n",
    "        Kpr = self.Kernelmtrx(self.Xtr_, Xtst) \n",
    "        w = self.alpha_\n",
    "        Xtst_red = np.dot(Kpr, w) \n",
    "        Xtst_red = Xtst_red.reshape(Xtst_red.shape[0],(Cl-1)) \n",
    "        return self.PrModel_.decision_function(Xtst_red)\n",
    "    def Kernelmtrx(self, Xtr, Xtst): #расчитывает kernel матрицу для векторов признаков 1ой группы объектов и 2ой, mxn\n",
    "        \"\"\"\n",
    "        input: Xtr - матрица признаков 1ой группы объектов nxk\n",
    "               Xtst - матрица признаков другой группы объектов mxk\n",
    "        \"\"\" \n",
    "        K = np.zeros((Xtst.shape[0], Xtr.shape[0]))\n",
    "        if (self.kernel == 'linear'):   #В случае linear kernel KFDA будет равносильно FDA\n",
    "            return np.dot(Xtst, Xtr.T)\n",
    "        if (self.kernel == 'RBF'):   #RBF kernel\n",
    "            D = scipy.spatial.distance.cdist(Xtst, Xtr, 'sqeuclidean')\n",
    "            K=exp(-0.5*D/(self.gamma*self.gamma))\n",
    "            return K\n",
    "        if (self.kernel =='Polynomial'): #K(x,y) = ((x, y.T) + b)^d\n",
    "                if (self.c == None): \n",
    "                    print (\"Введите свободный параметр c Polynomial Kernel\")\n",
    "                    self.c = int(input(),10)\n",
    "                if (self.d == None): \n",
    "                    print (\"Введите степень d Polynomial Kernel\")\n",
    "                    self.d = int(input(),10)\n",
    "                K = (np.dot(Xtst, Xtr.T)+ self.c)**(self.d)\n",
    "                return K\n",
    "    def transform(self, Xtst , Proj): \n",
    "        \"\"\"\n",
    "        input: Xtst - np.ndarray, матрица признаков объектов, для которых необх. предсказать класс, mxk\n",
    "               Proj - int, размерность подпространства, в которое проецируем: (Cl-1)<=Proj <=k\n",
    "        output: Xtst_red -  данные Xtst, спроецированные  в подпространство из Proj \"наилучших\" векторов, найденных КFDA(fit)\n",
    "               \n",
    "        \"\"\"\n",
    "        Cl = self.Cl_\n",
    "        Kpr = self.Kernelmtrx(self.Xtr_, Xtst) \n",
    "        w = self.alpha_[:,:Proj]\n",
    "        Xtst_red = np.dot(Kpr, w) \n",
    "        Xtst_red = Xtst_red.reshape(Xtst_red.shape[0],Proj)\n",
    "        return (Xtst_red)\n",
    "    def score(self, X, y, k=5, t = 1, gamma = 0):\n",
    "        \"\"\"\n",
    "        input: Xtst - np.ndarray, матрица тестовых объектов, mxk\n",
    "               y - истинные значения меток тестовых объектов\n",
    "        output: accuracy_score - float, ср. точность, с которой классификатор предсказывает метки классов\n",
    "               \n",
    "        \"\"\"\n",
    "        return accuracy_score(y, self.predict(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
